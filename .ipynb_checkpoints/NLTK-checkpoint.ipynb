{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a92a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08133224587104161\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "moby_raw = gutenberg.raw('melville-moby_dick.txt') \n",
    "\n",
    "def answer_one():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "lexical_diversity = answer_one()\n",
    "print(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b5f878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4125037250811676\n"
     ]
    }
   ],
   "source": [
    "def answer_two():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    whale_count = sum(1 for token in tokens if token in ['whale', 'Whale'])\n",
    "    return (whale_count / len(tokens)) * 100\n",
    "\n",
    "whale_percentage = answer_two()\n",
    "print(whale_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e8c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 19204), ('the', 13715), ('.', 7306), ('of', 6513), ('and', 6010), ('a', 4545), ('to', 4515), (';', 4173), ('in', 3908), ('that', 2978)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def answer_three():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    frequency = Counter(tokens)\n",
    "    return frequency.most_common(10)\n",
    "\n",
    "top_tokens = answer_three()\n",
    "print(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721a84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Captain', 'Pequod', 'Queequeg', 'Starbuck', 'almost', 'before', 'himself', 'little', 'seemed', 'should', 'though', 'through', 'whales', 'without']\n"
     ]
    }
   ],
   "source": [
    "def answer_four():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    freq = Counter(tokens)\n",
    "    return sorted([token for token in freq if len(token) > 5 and freq[token] > 150])\n",
    "\n",
    "custom_tokens = answer_four()\n",
    "print(custom_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03bfce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"twelve-o'clock-at-night\", 23)\n"
     ]
    }
   ],
   "source": [
    "def answer_five():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    longest_word = max(tokens, key=len)\n",
    "    return (longest_word, len(longest_word))\n",
    "\n",
    "longest_word = answer_five()\n",
    "print(longest_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd92a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13715, 'the'), (6513, 'of'), (6010, 'and'), (4545, 'a'), (4515, 'to'), (3908, 'in'), (2978, 'that'), (2459, 'his'), (2196, 'it'), (2113, 'I')]\n"
     ]
    }
   ],
   "source": [
    "def answer_six():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    freq = Counter(words)\n",
    "    return sorted([(freq[word], word) for word in set(words) if freq[word] > 2000], reverse=True)\n",
    "\n",
    "frequent_words = answer_six()\n",
    "print(frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb846fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.88591149005278\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "def answer_seven():\n",
    "    sentences = sent_tokenize(moby_raw)\n",
    "    token_counts = [len(word_tokenize(sentence)) for sentence in sentences]\n",
    "    return np.mean(token_counts)\n",
    "\n",
    "avg_tokens = answer_seven()\n",
    "print(avg_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67064a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 32727), ('IN', 28662), ('DT', 25879), (',', 19204), ('JJ', 17613)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "def answer_eight():\n",
    "    tokens = word_tokenize(moby_raw)\n",
    "    tags = pos_tag(tokens)\n",
    "    freq = Counter(tag for word, tag in tags)\n",
    "    return freq.most_common(5)\n",
    "\n",
    "parts_of_speech = answer_eight()\n",
    "print(parts_of_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "695fb310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpulent', 'intendence', 'validate']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words as nltk_words\n",
    "import nltk\n",
    "\n",
    "def answer_nine(default_words=['cormulent', 'incendenece', 'validrate']):\n",
    "    correct_spellings = nltk_words.words()\n",
    "    recommendations = []\n",
    "\n",
    "    for word in default_words:\n",
    "        same_letter_words = [w for w in correct_spellings if w.startswith(word[0].lower())]\n",
    "        distances = ((nltk.edit_distance(word, w, transpositions=True), w) for w in same_letter_words)\n",
    "        recommendation = min(distances, key=lambda x: x[0])[1]\n",
    "        recommendations.append(recommendation)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "spelling_recommendations = answer_nine()\n",
    "print(spelling_recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
